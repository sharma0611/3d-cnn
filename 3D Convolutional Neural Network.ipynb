{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Investigating-Architectures-of-3D-CNNs\" data-toc-modified-id=\"Investigating-Architectures-of-3D-CNNs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Investigating Architectures of 3D CNNs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Getting-the-Data\" data-toc-modified-id=\"Getting-the-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Getting the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sanity-Check\" data-toc-modified-id=\"Sanity-Check-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Sanity Check</a></span></li><li><span><a href=\"#Processing-Videos-to-Images\" data-toc-modified-id=\"Processing-Videos-to-Images-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Processing Videos to Images</a></span></li><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Train Test Split</a></span></li><li><span><a href=\"#Sanity-Check\" data-toc-modified-id=\"Sanity-Check-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Sanity Check</a></span></li><li><span><a href=\"#Investigating-Time-Complexity\" data-toc-modified-id=\"Investigating-Time-Complexity-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Investigating Time Complexity</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Data-Cleanse\" data-toc-modified-id=\"Data-Cleanse-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Data Cleanse</a></span></li><li><span><a href=\"#Training-From-Scratch\" data-toc-modified-id=\"Training-From-Scratch-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Training From Scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Definition\" data-toc-modified-id=\"Model-Definition-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Model Definition</a></span></li></ul></li><li><span><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Transfer Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-Weights\" data-toc-modified-id=\"Loading-the-Weights-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Loading the Weights</a></span></li><li><span><a href=\"#Sanity-Check\" data-toc-modified-id=\"Sanity-Check-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Sanity Check</a></span></li><li><span><a href=\"#Fine-Tuning\" data-toc-modified-id=\"Fine-Tuning-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>Fine Tuning</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0vKpYpjaEKJ"
   },
   "source": [
    "# Investigating Architectures of 3D CNNs\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1t8jXmUpaUHt",
    "outputId": "b1ae8fba-1808-4c25-8ebe-2c58a32f6297"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, Convolution3D, ZeroPadding3D\n",
    "from keras.layers.pooling import MaxPooling2D, MaxPooling3D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU, TimeDistributed, LSTM, Input, Reshape, Concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "LEGACY_DIR_PATH = r'/Volumes/Expansion/3dcnn'\n",
    "DIR_PATH = r'/Users/shivam/dev/3dcnn'\n",
    "\n",
    "DATA_PATH = os.path.join(DIR_PATH, 'ucfdata')\n",
    "METADATA_PATH = os.path.join(DIR_PATH, 'ucfmetadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lek15pI_aedt"
   },
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aS8bqM5hqL7T",
    "outputId": "2833cc37-3be2-460e-8997-1818d8ccad7d"
   },
   "outputs": [
    {
     "ename": "TIMEOUT",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timeout exceeded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTIMEOUT\u001b[0m: Timeout exceeded.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0m_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'(Go to this URL in a browser: https://.*)\\r\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34mu'Drive File Stream encountered a problem and has stopped'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     ])\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         return self.expect_list(compiled_pattern_list,\n\u001b[0;32m--> 341\u001b[0;31m                 timeout, searchwindowsize, async_)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     def expect_list(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mtimeout\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTIMEOUT\u001b[0m: Timeout exceeded.\n<pexpect.pty_spawn.spawn object at 0x7f83a4185f98>\ncommand: /bin/bash\nargs: [b'/bin/bash', b'--noediting']\nbuffer (last 100 chars): ':20:24.442ZI [140685539874560] curl_api.cc:550:Init Using cacerts from /opt/google/drive/roots.pem\\r\\n'\nbefore (last 100 chars): ':20:24.442ZI [140685539874560] curl_api.cc:550:Init Using cacerts from /opt/google/drive/roots.pem\\r\\n'\nafter: <class 'pexpect.exceptions.TIMEOUT'>\nmatch: None\nmatch_index: None\nexitstatus: None\nflag_eof: False\npid: 32306\nchild_fd: 79\nclosed: False\ntimeout: 120\ndelimiter: <class 'pexpect.exceptions.EOF'>\nlogfile: None\nlogfile_read: None\nlogfile_send: None\nmaxread: 1000000\nignorecase: False\nsearchwindowsize: None\ndelaybeforesend: 0.05\ndelayafterclose: 0.1\ndelayafterterminate: 0.1\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('root@0cb0feb91b09-ee38116cb39141b2904c96a1d18bf5b7: ')\n    2: re.compile('(Go to this URL in a browser: https://.*)\\r\\n')\n    3: re.compile('Drive File Stream encountered a problem and has stopped')"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DIR_PATH = '/content/drive/My Drive'\n",
    "DATA_PATH = os.path.join(DIR_PATH, 'ucfdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "XCLV3yCoZ7li",
    "outputId": "96a7ecab-716a-4ab4-b780-bb7e9d9e9961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-20 04:23:43--  http://crcv.ucf.edu/data/UCF101/UCF101.rar\n",
      "Resolving crcv.ucf.edu (crcv.ucf.edu)... 132.170.214.127\n",
      "Connecting to crcv.ucf.edu (crcv.ucf.edu)|132.170.214.127|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.crcv.ucf.edu/data/UCF101/UCF101.rar [following]\n",
      "--2019-07-20 04:23:44--  https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n",
      "Resolving www.crcv.ucf.edu (www.crcv.ucf.edu)... 132.170.214.127\n",
      "Connecting to www.crcv.ucf.edu (www.crcv.ucf.edu)|132.170.214.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6932971618 (6.5G) [application/rar]\n",
      "Saving to: ‘UCF101.rar’\n",
      "\n",
      "UCF101.rar          100%[===================>]   6.46G  5.18MB/s    in 15m 27s \n",
      "\n",
      "2019-07-20 04:39:11 (7.13 MB/s) - ‘UCF101.rar’ saved [6932971618/6932971618]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir {DATA_PATH}\n",
    "!cd {DATA_PATH} && wget http://crcv.ucf.edu/data/UCF101/UCF101.rar\n",
    "!cd {DATA_PATH} && unrar e UCF101.rar -idq\n",
    "!rm {DATA_PATH + '/UCF101.rar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "6i9hR9BJV5-y",
    "outputId": "b63fc327-48ee-48da-9693-4b61f8340bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-21 00:16:46--  http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip\n",
      "Resolving crcv.ucf.edu (crcv.ucf.edu)... 132.170.214.127\n",
      "Connecting to crcv.ucf.edu (crcv.ucf.edu)|132.170.214.127|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip [following]\n",
      "--2019-07-21 00:16:46--  https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip\n",
      "Resolving www.crcv.ucf.edu (www.crcv.ucf.edu)... 132.170.214.127\n",
      "Connecting to www.crcv.ucf.edu (www.crcv.ucf.edu)|132.170.214.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 113943 (111K) [application/zip]\n",
      "Saving to: ‘UCF101TrainTestSplits-RecognitionTask.zip’\n",
      "\n",
      "UCF101TrainTestSpli 100%[===================>] 111.27K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2019-07-21 00:16:47 (3.04 MB/s) - ‘UCF101TrainTestSplits-RecognitionTask.zip’ saved [113943/113943]\n",
      "\n",
      "Archive:  UCF101TrainTestSplits-RecognitionTask.zip\n",
      "   creating: ucfTrainTestlist/\n",
      "  inflating: ucfTrainTestlist/classInd.txt  \n",
      "  inflating: ucfTrainTestlist/testlist01.txt  \n",
      "  inflating: ucfTrainTestlist/testlist02.txt  \n",
      "  inflating: ucfTrainTestlist/testlist03.txt  \n",
      "  inflating: ucfTrainTestlist/trainlist01.txt  \n",
      "  inflating: ucfTrainTestlist/trainlist02.txt  \n",
      "  inflating: ucfTrainTestlist/trainlist03.txt  \n"
     ]
    }
   ],
   "source": [
    "!mkdir {METADATA_PATH}\n",
    "!cd {METADATA_PATH} && wget http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip\n",
    "!cd {METADATA_PATH} && unzip UCF101TrainTestSplits-RecognitionTask.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6h83w0aIFzy"
   },
   "source": [
    "### Sanity Check\n",
    "\n",
    "UCF101 dataset should contain 13K+ videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9H_0ZZW1xJ16",
    "outputId": "3d38ce58-e717-4636-e076-b8a111fd9629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13285\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {DATA_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ld4DvZY8kcct"
   },
   "source": [
    "### Processing Videos to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "9ly6Q8Azpr39",
    "outputId": "c6fa3369-c519-408f-ce22-14fd49e82586"
   },
   "outputs": [],
   "source": [
    "VIDEOS_PATH = DATA_PATH\n",
    "IMAGES_PATH = os.path.join(DIR_PATH, 'imgs')\n",
    "\n",
    "def create_empty_folder(target_folder):\n",
    "    if os.path.exists(target_folder):\n",
    "        shutil.rmtree(target_folder)\n",
    "\n",
    "    os.makedirs(target_folder)\n",
    "    \n",
    "def get_image_path(folder, num_frame):\n",
    "    return os.path.join(folder, str(num_frame) + '.jpg')\n",
    "\n",
    "def get_image_folder(video_title, images_dir=IMAGES_PATH):\n",
    "    [video_name, extension] = video_title.split(\".\")\n",
    "    if extension != 'avi':\n",
    "        raise Exception(\"File is not a video\")\n",
    "    [_, action, group, vid_num] = video_name.split(\"_\")\n",
    "    image_folder = os.path.join(images_dir,\"_\".join([action, group, vid_num]))\n",
    "    return image_folder\n",
    "\n",
    "def load_image(image_path):\n",
    "    if not os.path.isfile(image_path):\n",
    "        print(image_path)\n",
    "    bgr_img = cv2.imread(image_path)\n",
    "    #rbg_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "    return bgr_img\n",
    "\n",
    "def process_video_to_images(video_fp, target_folder):\n",
    "    \n",
    "    create_empty_folder(target_folder)\n",
    "  \n",
    "    cap = cv2.VideoCapture(video_fp)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for frame_num in range(frame_count):\n",
    "        _, frame = cap.read()\n",
    "        img_path = get_image_path(target_folder, frame_num)\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        \n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "def process_videos_to_images():\n",
    "    video_list = os.listdir(VIDEOS_PATH)\n",
    "  \n",
    "    video_data = []\n",
    "\n",
    "    for video_title in tqdm_notebook(video_list):\n",
    "        video_fp = os.path.join(VIDEOS_PATH, video_title)\n",
    "    \n",
    "        try:\n",
    "            image_folder = get_image_folder(video_title)\n",
    "        except:\n",
    "            print(\"Not a video: \" + str(video_title))\n",
    "            continue\n",
    "      \n",
    "        frame_count = process_video_to_images(video_fp, image_folder)\n",
    "    \n",
    "        video_data.append([video_fp, frame_count])\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSZT1SLKhvg1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef50c27433dd4c5eb195ef63cb04a637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_metadata = process_videos_to_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mzwj-7Kmf87T",
    "outputId": "960111b9-3f30-4ce5-bc97-07d0dac6f2c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>frame_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_CricketBowl...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_BreastStrok...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_TennisSwing...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_BrushingTee...</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_Typing_g08_...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp  frame_count\n",
       "0  /Volumes/Expansion/3dcnn/ucfdata/v_CricketBowl...          170\n",
       "1  /Volumes/Expansion/3dcnn/ucfdata/v_BreastStrok...          116\n",
       "2  /Volumes/Expansion/3dcnn/ucfdata/v_TennisSwing...          228\n",
       "3  /Volumes/Expansion/3dcnn/ucfdata/v_BrushingTee...          716\n",
       "4  /Volumes/Expansion/3dcnn/ucfdata/v_Typing_g08_...          250"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_md_df = pd.DataFrame(video_metadata)\n",
    "video_md_df.columns = ['fp', 'frame_count']\n",
    "#video_md_df['fp'] = video_md_df['fp'].str.replace('\\.\\/ucfdata', DATA_PATH) # delete this after\n",
    "video_md_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_md_df['fp'] = video_md_df['fp'].str.replace(LEGACY_DIR_PATH, DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>frame_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp  frame_count\n",
       "0  /Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...          120\n",
       "1  /Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...          117\n",
       "2  /Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...          146\n",
       "3  /Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...          224\n",
       "4  /Volumes/Expansion/3dcnn/ucfdata/v_ApplyEyeMak...          276"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_md_df = pd.concat([train_df, test_df])[['fp', 'frame_count']]\n",
    "video_md_df.drop_duplicates(inplace=True)\n",
    "video_md_df = video_md_df.reset_index()[['fp', 'frame_count']]\n",
    "video_md_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>frame_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp  frame_count\n",
       "0  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...          120\n",
       "1  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...          117\n",
       "2  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...          146\n",
       "3  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...          224\n",
       "4  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...          276"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_md_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPeXRjDYajV2"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoA_4gp5ahzk"
   },
   "outputs": [],
   "source": [
    "TRAIN_TEST_METADATA = os.path.join(METADATA_PATH, 'ucfTrainTestlist')\n",
    "TEST_SPLITS = ['testlist01.txt', 'testlist02.txt', 'testlist03.txt']\n",
    "TRAIN_SPLITS = ['trainlist01.txt', 'trainlist02.txt', 'trainlist03.txt']\n",
    "USE_SPLIT = 0\n",
    "CLASS_MAPPING = 'classInd.txt'\n",
    "\n",
    "def process_split_to_df(split_file):\n",
    "    class_map_fp = os.path.join(TRAIN_TEST_METADATA, CLASS_MAPPING)\n",
    "    class_map_df = pd.read_csv(class_map_fp, sep=\" \", header=None)\n",
    "    class_map_df.columns = ['class', 'class_name']\n",
    "    \n",
    "    # Make class labels from 0 to num_classes, as required for keras.utils.to_categorical\n",
    "    class_map_df['class'] = class_map_df['class'] - 1  \n",
    "  \n",
    "    fp = os.path.join(TRAIN_TEST_METADATA, split_file)\n",
    "    data = pd.read_csv(fp, sep=\" \", header=None)\n",
    "    data = data.iloc[:,:1]\n",
    "    data.columns = ['title']\n",
    "    title_split = data[\"title\"].str.split(\"\\/\", n = 1, expand = True) \n",
    "    data[\"fp\"] = DATA_PATH + '/' + title_split[1]\n",
    "    data[\"class_name\"] = title_split[0]\n",
    "    data = pd.merge(data,  class_map_df,left_on='class_name', right_on='class_name')\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_train_test_split(video_metadata):\n",
    "    test_split = TEST_SPLITS[USE_SPLIT]\n",
    "    train_split = TRAIN_SPLITS[USE_SPLIT]\n",
    "    test_df = process_split_to_df(test_split)\n",
    "    train_df = process_split_to_df(train_split)\n",
    "    video_metadata['fp'].str.split\n",
    "    test_df = pd.merge(test_df, video_metadata, left_on='fp', right_on='fp')\n",
    "    train_df = pd.merge(train_df, video_metadata, left_on='fp', right_on='fp')\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = get_train_test_split(video_md_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y2N4LK-1IbkM",
    "outputId": "04c60162-d488-4755-aaed-571a9925b57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9537, 5)\n",
      "(3783, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "V-o2PDUjVneV",
    "outputId": "a06bf9a9-40cc-4613-a6b1-7edab7cfe755"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>fp</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class</th>\n",
       "      <th>frame_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi   \n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi   \n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi   \n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi   \n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi   \n",
       "\n",
       "                                                  fp      class_name  class  \\\n",
       "0  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "1  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "2  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "3  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "4  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "\n",
       "   frame_count  \n",
       "0          120  \n",
       "1          117  \n",
       "2          146  \n",
       "3          224  \n",
       "4          276  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5Zfg7MBHr2W"
   },
   "outputs": [],
   "source": [
    "# Metadata filepaths\n",
    "train_df_fp = os.path.join(METADATA_PATH, 'train_df.csv')\n",
    "test_df_fp = os.path.join(METADATA_PATH, 'test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzmiTD8ik43U"
   },
   "outputs": [],
   "source": [
    "# Persist metadata\n",
    "train_df.to_csv(train_df_fp, index=False)\n",
    "test_df.to_csv(test_df_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iAKqe-CRzJH"
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "train_df = pd.read_csv(train_df_fp)\n",
    "test_df = pd.read_csv(test_df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0Swbtllk-K2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "IMG_HEIGHT = 112\n",
    "IMG_WIDTH = 112\n",
    "IMG_CHANNELS = 3\n",
    "FRAMES = 16\n",
    "NUM_CLASSES = 101\n",
    "\n",
    "class DataHandler(): \n",
    "    def __init__(self, test_df, train_df, img_height=IMG_HEIGHT,\n",
    "                 img_width=IMG_WIDTH, img_channels=IMG_CHANNELS, \n",
    "                 frames=FRAMES, num_classes=NUM_CLASSES, batch_size=BATCH_SIZE):\n",
    "        \n",
    "        self.test_df = test_df\n",
    "        self.train_df = train_df\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.img_channels = img_channels\n",
    "        self.frames = frames\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.use_preprocess_dir = False\n",
    "\n",
    "    def resize_image(self, image):\n",
    "        # input is (240,320,3) for UCF101 dataset\n",
    "        # Crop\n",
    "        image = image[:, 40:280]\n",
    "        # Resize\n",
    "        image = cv2.resize(image, (self.img_height, self.img_width))\n",
    "        return image\n",
    "    \n",
    "    def set_preprocess(self, preprocess_dir):\n",
    "        self.use_preprocess_dir = True\n",
    "        self.preprocess_dir = preprocess_dir\n",
    "\n",
    "    def preprocess(self, preprocess_dir):\n",
    "        create_empty_folder(preprocess_dir)\n",
    "        self.set_preprocess(preprocess_dir)      \n",
    "        for df in [self.train_df, self.test_df]:\n",
    "            with tqdm_notebook(total=len(df)) as pbar:\n",
    "                for row_idx, row in df.iterrows():\n",
    "                    pbar.update(1)\n",
    "                    video_title = row['title']\n",
    "                    image_folder = get_image_folder(video_title)\n",
    "\n",
    "                    preprocess_image_folder = get_image_folder(video_title, preprocess_dir)\n",
    "                    create_empty_folder(preprocess_image_folder)\n",
    "                    \n",
    "                    frame_count = row['frame_count']\n",
    "                    for frame_num in range(frame_count):\n",
    "                        image_path = get_image_path(image_folder, frame_num)\n",
    "                        image = load_image(image_path)\n",
    "                        try:\n",
    "                            preprocess_image = self.resize_image(image)\n",
    "                            preprocess_image_path = get_image_path(preprocess_image_folder, frame_num)\n",
    "                            cv2.imwrite(preprocess_image_path, preprocess_image)\n",
    "                        except:\n",
    "                            print(image_path)\n",
    "    \n",
    "    def cleanse_train_test_df(self):\n",
    "        # Make sure frame counts do not include trailing black frames\n",
    "        frames_cleansed = 0\n",
    "        for df in [self.train_df, self.test_df]:\n",
    "            new_frames = []\n",
    "            with tqdm_notebook(total=len(df)) as pbar:\n",
    "                for row_idx, row in df.iterrows():\n",
    "                    pbar.update(1)\n",
    "                    video_title = row['title']\n",
    "                    frame_count = row['frame_count']\n",
    "                    prev_frame_count = frame_count\n",
    "                    image_folder = get_image_folder(video_title)\n",
    "                    if self.use_preprocess_dir:\n",
    "                        image_folder = get_image_folder(video_title, self.preprocess_dir)\n",
    "                    \n",
    "                    frames = [\".\".join(f.split(\".\")[:-1]) for f in os.listdir(image_folder)]\n",
    "                    frames = [int(x) for x in frames]\n",
    "                    \n",
    "                    max_frame = max(frames)\n",
    "                    \n",
    "                    if frame_count > max_frame:\n",
    "                        frame_count = max_frame\n",
    "                    \n",
    "                    while frame_count > 0:\n",
    "                        image_path = get_image_path(image_folder, frame_count)\n",
    "                        frame = load_image(image_path)\n",
    "                        if np.sum(frame) != 0:\n",
    "                            break\n",
    "                        frame_count -= 1\n",
    "                    new_frames.append(frame_count)\n",
    "                    frames_cleansed += prev_frame_count - frame_count\n",
    "                    \n",
    "            df['frame_count'] = new_frames\n",
    "        \n",
    "        print(\"# of Frames Cleansed from Data: %d \" % frames_cleansed)\n",
    "        return [self.train_df, self.test_df]\n",
    "    \n",
    "    def create_generator(self, df):\n",
    "        \n",
    "        input_batch = np.zeros((self.batch_size, self.frames, self.img_height,\n",
    "                            self.img_width, self.img_channels))\n",
    "    \n",
    "        output_batch = np.zeros((self.batch_size, 1))\n",
    "        \n",
    "        while True:\n",
    "            for batch_num in range(self.batch_size):\n",
    "                # pick a random video from our df\n",
    "                video_idx = np.random.randint(0, len(df) - 1)\n",
    "\n",
    "                # get the image folder\n",
    "                row = df.iloc[video_idx]\n",
    "                video_title = row['title']\n",
    "                image_folder = get_image_folder(video_title)\n",
    "                if self.use_preprocess_dir:\n",
    "                    image_folder = get_image_folder(video_title, self.preprocess_dir)\n",
    "\n",
    "                # get the label for the video\n",
    "                output_batch[batch_num] = row['class']\n",
    "\n",
    "                # pick a random spot in the video\n",
    "                frame_count = row['frame_count']\n",
    "                base_frame_idx = np.random.randint(0, frame_count - 1 - self.frames)\n",
    "\n",
    "                # take the next 16 frames from this spot\n",
    "                for frame_num in range(self.frames):\n",
    "                    curr_frame_num = base_frame_idx + frame_num\n",
    "                    \n",
    "                    # get image path\n",
    "                    image_path = get_image_path(image_folder, curr_frame_num)\n",
    "\n",
    "                    # load image\n",
    "                    image = load_image(image_path)\n",
    "\n",
    "                    # preprocess\n",
    "                    if not self.use_preprocess_dir:\n",
    "                        image = self.resize_image(image)\n",
    "    \n",
    "                    # add to batch\n",
    "                    input_batch[batch_num][frame_num] = image\n",
    "\n",
    "            yield (input_batch, to_categorical(output_batch, num_classes=self.num_classes))\n",
    "\n",
    "      \n",
    "    def create_test_generator(self):\n",
    "        df = self.test_df\n",
    "        return self.create_generator(df)\n",
    "    \n",
    "    def create_train_generator(self):\n",
    "        df = self.train_df\n",
    "        return self.create_generator(df)\n",
    "    \n",
    "DH = DataHandler(test_df, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "\n",
    "The input batch should be of size 30, with 16 frames, each 128x128 with 3 channels.\n",
    "\n",
    "The output batch should be of size 30, each with a categorical vector of size 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7kkaEhgJXPJ6",
    "outputId": "8e9fd34a-08d0-4530-db6c-99afb45472b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 16, 112, 112, 3)\n",
      "(30, 101)\n",
      "1.220026969909668\n"
     ]
    }
   ],
   "source": [
    "def verify_data_generators(DH):\n",
    "    gen = DH.create_train_generator()\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(next(gen)[0].shape)\n",
    "    t2 = time.time()\n",
    "    print(next(gen)[1].shape)\n",
    "    print(t2-t1)\n",
    "\n",
    "verify_data_generators(DH)\n",
    "# 3.83 seconds for a single batch on HDD\n",
    "# for 1000 steps, 25 epochs, we can expect 20 hours for just loading the data\n",
    "# This is way too slow... Let's stop using an external drive or let's preprocess the data beforehand.\n",
    "# After moving all the data to my SSD, the time is now 1.2s for a single batch. This will be about 8 hours of processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Time Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loading raw image: 0.00776 (s)\n",
      "Time for loading preprocessed image: 0.00035 (s)\n",
      "Loading the preprocessed image is 22.24 x faster\n"
     ]
    }
   ],
   "source": [
    "def compare_loading_times():\n",
    "    row_idx = np.random.randint(0, len(train_df))\n",
    "    row = train_df.iloc[row_idx]\n",
    "    video_title = row['title']\n",
    "\n",
    "    image_folder = get_image_folder(video_title)\n",
    "    image_path = get_image_path(image_folder, 0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    img1 = load_image(image_path)\n",
    "    a = time.time() - t1\n",
    "    print(\"Time for loading raw image: %.5f (s)\" % a)\n",
    "    resized_img = DH.resize_image(img1)\n",
    "    cv2.imwrite('test.jpg', resized_img)\n",
    "    t1 = time.time()\n",
    "    img2 = load_image('test.jpg')\n",
    "    b = time.time() - t1\n",
    "    print(\"Time for loading preprocessed image: %.5f (s)\" % b)\n",
    "    c = a/b\n",
    "    print(\"Loading the preprocessed image is %.2f x faster\" % c)\n",
    "    \n",
    "    \n",
    "compare_loading_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESS_DIR = os.path.join(DIR_PATH, 'preprocess')\n",
    "DH.set_preprocess(PREPROCESS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(PREPROCESS_DIR):\n",
    "    DH.preprocess(PREPROCESS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c505d33bc75437781c5a25d11a5280f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9537), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d54f4eb7f44afb85b7c0b7ee8f09e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3783), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Frames Cleansed from Data: 13320 \n"
     ]
    }
   ],
   "source": [
    "[train_df, test_df] = DH.cleanse_train_test_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>fp</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class</th>\n",
       "      <th>frame_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi</td>\n",
       "      <td>/Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi   \n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi   \n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi   \n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi   \n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi   \n",
       "\n",
       "                                                  fp      class_name  class  \\\n",
       "0  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "1  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "2  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "3  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "4  /Users/shivam/dev/3dcnn/ucfdata/v_ApplyEyeMake...  ApplyEyeMakeup      0   \n",
       "\n",
       "   frame_count  \n",
       "0          119  \n",
       "1          116  \n",
       "2          145  \n",
       "3          223  \n",
       "4          275  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 16, 112, 112, 3)\n",
      "(30, 101)\n",
      "0.5413329601287842\n"
     ]
    }
   ],
   "source": [
    "verify_data_generators(DH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it takes approximately 0.5 seconds to load a batch. This is a much needed improvement.\n",
    "The total time for loading the data for all epochs is now ~3.4 hours from an original ~20 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W86ZwHC1IJrN"
   },
   "source": [
    "\n",
    "## Training From Scratch\n",
    "\n",
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8_91iSElY0aN",
    "outputId": "49361fc2-2eeb-4ad0-ce63-3f9e5c10f601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "classify (Dense)             (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_3d():\n",
    "    input_shape = (FRAMES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "     \n",
    "    # Normalize \n",
    "    #model.add(Lambda(lambda x: x / 127.5 - 1, input_shape=input_shape, name=\"normalize\"))   \n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution3D(64, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv1',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           padding='valid', name='pool1'))\n",
    "    # 2nd layer group\n",
    "    model.add(Convolution3D(128, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool2'))\n",
    "    # 3rd layer group\n",
    "    model.add(Convolution3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3a'))\n",
    "    model.add(Convolution3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool3'))\n",
    "    # 4th layer group\n",
    "    model.add(Convolution3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4a'))\n",
    "    model.add(Convolution3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool4'))\n",
    "    # 5th layer group\n",
    "    model.add(Convolution3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5a'))\n",
    "    model.add(Convolution3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5b'))\n",
    "    \n",
    "    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # FC layers group\n",
    "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(.5))\n",
    "#     model.add(Dense(487, activation='softmax', name='fc8'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', name='classify'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = cnn_3d()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "MiZRHLYIccgx",
    "outputId": "83abd16b-c5f6-4351-dfb7-8988d153847d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 00:34:45.286726 4503860672 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 80/958 [=>............................] - ETA: 38:16:44 - loss: 4.6917 - acc: 0.0104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-0ec908c2dd7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     validation_steps=len(test_df) // BATCH_SIZE)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator = DH.create_train_generator()\n",
    "test_generator = DH.create_test_generator()\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "#sgd = SGD(lr=1e-5, decay=0.0005, momentum=0.9)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_df) // BATCH_SIZE,\n",
    "    epochs=25,\n",
    "    #callbacks=callbacks_list,\n",
    "    verbose=1, \n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_df) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning \n",
    "\n",
    "Let's take model weights learned on the sports-1M dataset.\n",
    "\n",
    "### Loading the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(DIR_PATH, 'models')\n",
    "SPORTS1M_WEIGHTS_PATH = os.path.join(MODEL_DIR, 'sports1m.h5')\n",
    "\n",
    "transfer_model = cnn_3d()\n",
    "transfer_model.load_weights(SPORTS1M_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    def __init__(self):\n",
    "        class_map_fp = os.path.join(TRAIN_TEST_METADATA, CLASS_MAPPING)\n",
    "        class_map_df = pd.read_csv(class_map_fp, sep=\" \", header=None)\n",
    "        class_map_df.columns = ['class', 'class_name']\n",
    "        # Make class labels from 0 to num_classes\n",
    "        class_map_df['class'] = class_map_df['class'] - 1\n",
    "        class_map = dict(zip(class_map_df['class'], class_map_df['class_name']))\n",
    "        self.class_map = class_map\n",
    "    \n",
    "    def predict_class(self, model, example):\n",
    "        prediction_softmax = model.predict(example)\n",
    "        predicted_class = np.argmax(prediction_softmax)\n",
    "        return predicted_class\n",
    "    \n",
    "    def predict_class_name(self, model, example):\n",
    "        predicted_class = self.predict_class(model, example)\n",
    "        predicted_class_name = self.class_map[predicted_class]\n",
    "        return predicted_class_name\n",
    "    \n",
    "MM = ModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diving'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = np.zeros((1, 16, 112, 112, 3))\n",
    "MM.predict_class_name(transfer_model, dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "classify (Dense)             (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 413,797\n",
      "Non-trainable params: 77,995,776\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      " 11/317 [>.............................] - ETA: 10:05:04 - loss: 15.9716 - acc: 0.0091"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-9535320e0d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     validation_steps=len(test_df) // BATCH_SIZE)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator = DH.create_train_generator()\n",
    "test_generator = DH.create_test_generator()\n",
    "\n",
    "adam = Adam()\n",
    "\n",
    "for layer in transfer_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "transfer_model.summary()\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_df) // BATCH_SIZE,\n",
    "    epochs=25,\n",
    "    #callbacks=callbacks_list,\n",
    "    verbose=1, \n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_df) // BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3D Convolutional Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "csenv",
   "language": "python",
   "name": "csenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
